\documentclass[12pt]{article}

\usepackage[utf8]{inputenc}
\usepackage{geometry}
\geometry{
    a4paper,
    total={170mm,257mm},
    left=25mm,
    right=25mm,
    top=25mm,
    bottom=25mm,
}
\usepackage{multicol}
\usepackage[font=small,labelfont=bf]{caption}
\setlength{\columnsep}{0.25cm}
\usepackage[inline]{enumitem}
\usepackage{amssymb}
\usepackage{xcolor}
\usepackage{mathtools} 
\setlength{\parindent}{0em}
\setlength{\parsep}{0em}
\usepackage{tikz}
\setlength{\parskip}{0em}
\usetikzlibrary{decorations.pathmorphing,patterns}
\usepackage[american,cuteinductors]{circuitikz}
\usetikzlibrary{shapes,arrows,circuits,calc,babel}
% Definition of blocks:
\tikzset{%
  block/.style    = {draw, thick, rectangle, minimum height = 3em,
    minimum width = 3em},
  sum/.style      = {draw, circle, node distance = 2cm}, % Adder
  input/.style    = {coordinate}, % Input
  output/.style   = {coordinate} % Output
}
% Defining string as labels of certain blocks.
\newcommand{\suma}{\Large$+$}
\newcommand{\inte}{$\displaystyle \int$}
\newcommand{\derv}{\huge$\frac{d}{dt}$}

\def\mf{\ensuremath\mathbf}
\def\mb{\ensuremath\mathbb}
\def\mc{\ensuremath\mathcal}
\def\lp{\ensuremath\left(}
\def\rp{\ensuremath\right)}
\def\lv{\ensuremath\left\lvert}
\def\rv{\ensuremath\right\rvert}
\def\lV{\ensuremath\left\lVert}
\def\rV{\ensuremath\right\rVert}
\def\lc{\ensuremath\left\{}
\def\rc{\ensuremath\right\}}
\def\ls{\ensuremath\left[}
\def\rs{\ensuremath\right]}
\def\bmx{\ensuremath\begin{bmatrix*}[r]}
\def\emx{\ensuremath\end{bmatrix*}}
\def\bmxc{\ensuremath\begin{bmatrix*}[c]}
\def\emxc{\ensuremath\end{bmatrix*}}
% \def\t{\lp t\rp}
% \def\k{\ls k\rs}

\newcommand{\demoex}[2]{\onslide<#1->\begin{color}{black!60} #2 \end{color}}
\newcommand{\demoexc}[3]{\onslide<#1->\begin{color}{#2} #3 \end{color}}
\newcommand{\anim}[3]{\onslide<#1->{\begin{color}{#2!60} #3 \end{color}}}
\newcommand{\ct}[1]{\lp #1\rp}
\newcommand{\dt}[1]{\ls #1\rs}

% \renewcommand{\familydefault}{\sfdefault}

\begin{document}
\begin{center}
\begin{large}
\textbf{Applied Linear Algebra in Data Analaysis}\\
\vspace{0.1cm}
\end{large}
\textbf{Orthogonality \& Matrix Inverses Assignment}
\end{center}
\hrule
\vspace{1em}

\begin{large}
    \textbf{Marks: 23}
\end{large}

\begin{enumerate}
  \item Consider an orthonormal set of vectors,
  \[ V = \left\{ \mf{v}_1, \mf{v}_2, \ldots \mf{v}_r\right\} \quad \mf{v}_i \in \mb{R}^n \quad \forall i \in \left\{1, 2, \ldots r\right\}\]
  If there is a vector $\mf{w} \in \mb{R}^n$ such that $\mf{v}_i^T\mf{w} = 0\,\,\,\forall i \in \left\{1, 2, \ldots r\right\}$. Prove that $\mf{w} \notin span\left(V\right)$. \textbf{[Marks: 1]}

  \item For a matrix $\mf{A} \in \mb{R}^{m \times n}$, prove that $C\lp\mf{A}\rp \perp N\lp\mf{A}^T\rp$ and $C\lp\mf{A}^T\rp \perp N\lp\mf{A}\rp$. \textbf{[Marks: 2]}

  \item If the columns of a matrix $\mf{A} \in \mb{R}^{n \times n}$ are orthonormal, prove that $\mf{A}^{-1} = \mf{A}^T$. What is $\mf{A}^T\mf{A}$ when $\mf{A}$ is rectangular $\left(\mf{A} \in \mb{R}^{m \times n}\right)$ with orthonormal columns? \textbf{[Marks: 2]}

  \item What will happen when the Gram-Schmidt procedure is applied to: (a) orthonormal set of vectors; and (b) orthogonal set of vectors? If the set of vectors are columns of a matrix $\mf{A}$, then what are the corresponding $\mf{Q}$ and $\mf{R}$ matrices for the orthonormal and orthogonal cases? \textbf{[Marks: 2]}

  \item Prove that the rank of an orthogonal projection matrix $\mf{P}_{S} = \mf{UU}^T$ onto a subspace $\mc{S}$ is equal to the $\text{dim } \mc{S}$, where the columns of $\mf{U}$ form an orthonormal basis of $\mc{S}$. \textbf{[Marks: 1]}

  \item If the columns of $\mf{A} \in \mb{R}^{m \times n}$ represent a basis for the subspace $\mc{S} \subset \mb{R}^m$. Find the orthogonal projection matrix $\mf{P}_\mc{S}$ onto the subspace $\mc{S}$. Hint: Gram-Schmidt orthogonalization. \textbf{[Marks: 1]}

  \item Consider two orthogornal matrices $\mf{Q}_1$ and $\mf{Q}_2$. Is the $\mf{Q}_2^T\mf{Q}_1$ an orthogonal matrix? If yes, prove that it is so, else provide a counter-example showing $\mf{Q}_2^T\mf{Q}_1$ is not orthogonal. \textbf{[Marks: 1]}

  \item Consider a 1 dimensional subspace spanned by the vector $\mf{u} \in \mb{R}^n$. What kind of a geometric operation does the matrix $\mf{I} - 2\frac{\mf{u}\mf{u}^T}{\mf{u}^T\mf{u}}$ represent? \textbf{[Marks: 1]}

  \item Prove that when a triangular matrix is orthogonal, it is diagonal. \textbf{[Marks: 1]}

  \item When does the following diagnoal matrix have an inverse? \textbf{[Marks: 1]}
  \[ \mf{D} = \begin{bmatrix*}
  d_1 & 0 & \cdots & 0\\
  0 & d_2 & \cdots & 0\\
  \vdots & \vdots & \ddots & \vdots\\
  0 & 0 & \cdots & d_n\\\end{bmatrix*} \]
  Write down an expression for $\mf{D}^{-1}$.
  
  \item Consider a $2 \times 2$ block matrix, $\mf{A} = \bmx \mf{B} & \mf{C}\\\mf{D} & \mf{E}\emx$, where $\mf{A} \in \mb{R}^{m \times m}$. Find an expression for the inverse $\mf{A}^{-1}$ interms of the block components and their inverses of $\mf{A}$. Hint: Consider $\mf{A}^{-1} = \bmx \mf{P} & \mf{Q}\\ \mf{R} & \mf{S}\emx$, and solve $\mf{A}\mf{A}^{-1} = \mf{I}$. \textbf{[Marks: 1]}

  \item Consider a matrix $\mf{A} \in \mathbb{R}^{m \times n}$ with linearly independent columns. Prove that the Gram matrix $\mf{A}^T\mf{A}$ is invertible. \textbf{[Marks: 1]}

  \item Consider the scalar equation, $ax = ay$. Here we can cancel $a$ from the equation when $a \neq 0$. When can we carry out similar cancellations for matrcies? \textbf{[Marks: 2]}
  \begin{enumerate}
      \item $\mf{A}\mf{X} = \mf{A}\mf{Y}$. Prove that here $\mf{X}=\mf{Y}$ only when $\mf{A}$ is left invertible.
      \item $\mf{X}\mf{A} = \mf{Y}\mf{A}$. Prove that here $\mf{X}=\mf{Y}$ only when $\mf{A}$ is right invertible.
  \end{enumerate}

  \item Consider two non-singular matrices $\mf{A}, \mf{B} \in \mb{R}^{n \times n}$. Explain whether or not the following matrices are invertible. If they are, then provide an expression for it inverse. \textbf{[Marks: 4]}
  \begin{enumerate}
      \item $\mf{C} = \mf{A} + \mf{B}$
      \item $\mf{C} = \bmx \mf{A} & \mf{0}\\\mf{0} & \mf{B}\emx$
      \item $\mf{C} = \bmx \mf{A} & \mf{A} + \mf{B}\\\mf{0} & \mf{B}\emx$
      \item $\mf{C} = \mf{A}\mf{B}\mf{A}$
  \end{enumerate}

  \item For a square matrix $\mf{A}$ with non-signular $\mf{I} - \mf{A}$, prove that, \textbf{[Marks: 1]}
  \[ \mf{A}\lp\mf{I} - \mf{A}\rp^{-1} = \lp\mf{I} - \mf{A}\rp^{-1}\mf{A} \]

  \item Consider the non-singular matrices $\mf{A}$, $\mf{B}$ and $\mf{A} + \mf{B}$. Prove that, \textbf{[Marks: 1]}
  \[ \mf{A}\lp\mf{A} + \mf{B}\rp^{-1}\mf{B} = \mf{B}\lp\mf{A} + \mf{B}\rp^{-1}\mf{A} = \lp\mf{A}^{-1} + \mf{B}^{-1}\rp^{-1} \]

\end{enumerate}

\end{document}